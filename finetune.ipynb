{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d998e535-0f61-4889-9954-80bdfbac312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_ID = 'labor_market_v1'\n",
    "CLASSIFY_TARGET = 'job_search_status'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bac04-fa74-403a-9fdb-18c7b8789f1c",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b7a91f-3eaf-431b-be73-5ede44131c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label encodings\n",
    "import yaml\n",
    "with open('label_maps.yaml', 'r') as file:\n",
    "    yaml_dict = [x for x in yaml.safe_load(file)[PROMPT_ID] if x['model'] == CLASSIFY_TARGET][0]\n",
    "\n",
    "label_encoding_map = pd.DataFrame.from_dict(yaml_dict['map'])\n",
    "test_examples = yaml_dict['examples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d9d7c5-ed8f-4711-961d-62a446a5d92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>value</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_118xr9s</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering going back to the same...</td>\n",
       "      <td>Would you go back to a company you had already...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_rwpsfy</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user expresses frustration with talent acq...</td>\n",
       "      <td>MY RESUME OUTLINES MY EXPERIENCE, SO DO NOT SE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_10p8ox3</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering leaving their current ...</td>\n",
       "      <td>Wait to be fired or quit?\\nLong story short—I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_17japq3</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering leaving their current ...</td>\n",
       "      <td>My boss is always shouting at me\\nHello, I jus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_vh2pl2</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user mentions struggling to find a part-ti...</td>\n",
       "      <td>How the hell do I get a job as a 15 year old w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12124</th>\n",
       "      <td>b5577o</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions receiving two job offers wit...</td>\n",
       "      <td>Careers working in environmental conservation/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12125</th>\n",
       "      <td>dguen7</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions accepting a new job offer an...</td>\n",
       "      <td>Just accepted a job offer, and will be giving ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12126</th>\n",
       "      <td>t3_qzwqah</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions receiving a job offer with \"...</td>\n",
       "      <td>After 2 months, I finally got an offer!!\\nFor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12127</th>\n",
       "      <td>t3_xgmjf0</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions receiving a job offer.</td>\n",
       "      <td>Recruiter is pressuring me to accept the job b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>facpsw</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions being offered a new job at t...</td>\n",
       "      <td>Got offered job at the interview !\\nIt is a hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12129 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                           value  \\\n",
       "0      t3_118xr9s    searching/considering search   \n",
       "1       t3_rwpsfy    searching/considering search   \n",
       "2      t3_10p8ox3    searching/considering search   \n",
       "3      t3_17japq3    searching/considering search   \n",
       "4       t3_vh2pl2    searching/considering search   \n",
       "...           ...                             ...   \n",
       "12124      b5577o  received offer/started new job   \n",
       "12125      dguen7  received offer/started new job   \n",
       "12126   t3_qzwqah  received offer/started new job   \n",
       "12127   t3_xgmjf0  received offer/started new job   \n",
       "12128      facpsw  received offer/started new job   \n",
       "\n",
       "                                               rationale  \\\n",
       "0      The user is considering going back to the same...   \n",
       "1      The user expresses frustration with talent acq...   \n",
       "2      The user is considering leaving their current ...   \n",
       "3      The user is considering leaving their current ...   \n",
       "4      The user mentions struggling to find a part-ti...   \n",
       "...                                                  ...   \n",
       "12124  The user mentions receiving two job offers wit...   \n",
       "12125  The user mentions accepting a new job offer an...   \n",
       "12126  The user mentions receiving a job offer with \"...   \n",
       "12127           The user mentions receiving a job offer.   \n",
       "12128  The user mentions being offered a new job at t...   \n",
       "\n",
       "                                              input_text  label_encode  \n",
       "0      Would you go back to a company you had already...             1  \n",
       "1      MY RESUME OUTLINES MY EXPERIENCE, SO DO NOT SE...             1  \n",
       "2      Wait to be fired or quit?\\nLong story short—I ...             1  \n",
       "3      My boss is always shouting at me\\nHello, I jus...             1  \n",
       "4      How the hell do I get a job as a 15 year old w...             1  \n",
       "...                                                  ...           ...  \n",
       "12124  Careers working in environmental conservation/...             0  \n",
       "12125  Just accepted a job offer, and will be giving ...             0  \n",
       "12126  After 2 months, I finally got an offer!!\\nFor ...             0  \n",
       "12127  Recruiter is pressuring me to accept the job b...             0  \n",
       "12128  Got offered job at the interview !\\nIt is a hi...             0  \n",
       "\n",
       "[12129 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "from helpers.db import get_postgres_query\n",
    "\n",
    "input_data = get_postgres_query(\n",
    "    f\"\"\"\n",
    "    WITH t0 AS (\n",
    "        SELECT \n",
    "            a.post_id, a.label_value AS value, a.label_rationale AS rationale,\n",
    "            CONCAT(TRIM(b.title), '\\n', REGEXP_REPLACE(TRIM(b.selftext), '[\\t\\n\\r]', ' ', 'g')) AS input_text\n",
    "        FROM text_scraper_reddit_llm_scores_v2 a\n",
    "        INNER JOIN text_scraper_reddit_scrapes b\n",
    "            ON a.scrape_id = b.scrape_id\n",
    "        WHERE a.PROMPT_ID = '{PROMPT_ID}' AND a.label_key = '{CLASSIFY_TARGET}'\n",
    "    )\n",
    "    -- Select where expected token count <= 512\n",
    "    SELECT * FROM t0\n",
    "    WHERE ARRAY_LENGTH(REGEXP_SPLIT_TO_ARRAY(input_text, '\\\\s+'), 1) * 1.5 <= 512\n",
    "    \"\"\"\n",
    "    ).merge(label_encoding_map, how = 'inner', on = 'value')\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfc4c5-bff1-4697-9e6b-5c7034b5786c",
   "metadata": {},
   "source": [
    "## Get Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a561cbc-78ce-4659-b959-61f28de1772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11685891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels = len(label_encoding_map)).to(device)\n",
    "\n",
    "# Num params\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d85c79-8f1f-4ed2-985a-a877f324fe0e",
   "metadata": {},
   "source": [
    "## Create Datasets & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0a7f61-6955-4918-920e-5ef55223cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Batch size\n",
    "B = 16\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, texts, labels = None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.inputs = self.tokenize_and_encode()\n",
    "        \n",
    "        if labels is not None:\n",
    "            self.labels = torch.tensor(labels, dtype = torch.long)\n",
    "        else:\n",
    "            self.labels = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def tokenize_and_encode(self):\n",
    "        return self.tokenizer(\n",
    "            self.texts,\n",
    "            add_special_tokens = True,\n",
    "            max_length = 512,\n",
    "            truncation = True,\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: vals[idx] for key, vals in self.inputs.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_df, val_df = train_test_split(input_data, test_size = .2, random_state = 1)\n",
    "train_ds, val_ds = [TextDataset(tokenizer, x['input_text'].tolist(), x['label_encode'].tolist()) for x in [train_df, val_df]]\n",
    "train_dl, val_dl = [DataLoader(x, batch_size = B) for x in [train_ds, val_ds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c392730-58c7-40b8-b5e2-25905f88bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = received offer/started new job\n",
    "# 1 = searching/considering search\n",
    "# 2 = not/unknown\n",
    "# print(val_ds.texts[6], val_ds.labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a77ea3e-44b3-42c6-8f0c-e029c46225b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>value</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>t3_y33u61</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering how future employers w...</td>\n",
       "      <td>Recently Fired for poor performance. Will futu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id                         value  \\\n",
       "3780  t3_y33u61  searching/considering search   \n",
       "\n",
       "                                              rationale  \\\n",
       "3780  The user is considering how future employers w...   \n",
       "\n",
       "                                             input_text  label_encode  \n",
       "3780  Recently Fired for poor performance. Will futu...             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70851791-8bfe-4e07-8c18-e411e31153a7",
   "metadata": {},
   "source": [
    "## Create Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80490ae2-1492-47af-a229-be9d9c6e627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2426it [00:52, 46.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_nll': 0.8204346, 'accuracy': 0.7765869744435284, 'count': 2426}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_performance_on_ds(model, ds, batch_size = 16):\n",
    "    \"\"\"\n",
    "    Test model performance on evaluation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_obs = 0\n",
    "    total_correct = 0\n",
    "    nlls = []\n",
    "\n",
    "    dl = DataLoader(ds, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    for step, b in tqdm(enumerate(dl)):\n",
    "        outputs = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "        logits = outputs['logits'].cpu()\n",
    "        label_ids = b['labels'].cpu()\n",
    "        \n",
    "        total_obs += len(label_ids)\n",
    "        total_correct += np.sum(np.where(np.argmax(logits, axis = 1) == label_ids, 1, 0))\n",
    "        nlls.append(F.cross_entropy(logits, label_ids))\n",
    "    \n",
    "    res = {'mean_nll': np.mean(nlls), 'accuracy': total_correct/total_obs, 'count': total_obs}\n",
    "    return res\n",
    "\n",
    "eval_performance_on_ds(model, val_ds, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383cbbc1-ae63-4b6e-8a46-c6f9e562856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "✅ [0.57] - Started searching for jobs and struggling\n",
      "❌ [0.21] - Just received a new job offer!\n",
      "❌ [0.25] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.21] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "❌ [0.26] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.49] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_performance_on_examples(model, examples):\n",
    "    \"\"\"\n",
    "    Run inference on a handful of predefined examples. Returns a printable string.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    str = ''\n",
    "    \n",
    "    inference_examples = [x['text'] for x in test_examples]\n",
    "    labels = [x['label'] for x in test_examples]\n",
    "    inference_dl = DataLoader(TextDataset(tokenizer, inference_examples, labels), 1, shuffle = True)\n",
    "    \n",
    "    for i, b in enumerate(inference_dl):\n",
    "        out = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "        softmax = F.softmax(out['logits'].detach().cpu().flatten(), dim = 0)\n",
    "        label = b['labels'].cpu()\n",
    "\n",
    "        is_correct = 1 if np.argmax(softmax) == label else 0\n",
    "        total_correct = total_correct + is_correct\n",
    "        str += (f'\\n{\"✅\" if is_correct == 1 else \"❌\"} {softmax[label].numpy().round(2)} - {inference_examples[i]}')\n",
    "\n",
    "    return f\"Correct: {total_correct}/{len(inference_examples)}\" + str\n",
    "    \n",
    "print(eval_performance_on_examples(model, test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c47f96-ab83-4020-8e38-1df6a1bad820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5011712, 8.589410304]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.555697152, 8.589410304]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([x/1e9 for x in torch.cuda.mem_get_info()])\n",
    "torch.cuda.empty_cache()\n",
    "[x/1e9 for x in torch.cuda.mem_get_info()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58139a-fb03-4d2c-a6d7-8181e3c3905d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a2c8f6-e2b4-4aee-998a-72d8a99f916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves directory\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "save_dir = f\"saves/{str(PROMPT_ID).rjust(2, '0')}-{CLASSIFY_TARGET}-{date.today().strftime('%Y%m%d')}\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd3dbf4-7ac3-4df6-a188-19bc58c3b3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bcd1395f904340b3e9be84a9f4a958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': '16021d60-83f4-4ef4-adf7-b745e1b2347f', 'x': [], 'y': []}],\n",
       "    'layout': {'template': '...'}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [11:11,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100/607 | Last 50 batch train NLL: 0.6348839536309242 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [11:18,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "✅ [0.75] - Started searching for jobs and struggling\n",
      "✅ [0.72] - Just received a new job offer!\n",
      "❌ [0.06] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.12] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "❌ [0.03] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "❌ [0.17] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [22:26,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200/607 | Last 50 batch train NLL: 0.6055583009123802 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [22:34,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "❌ [0.26] - Started searching for jobs and struggling\n",
      "❌ [0.01] - Just received a new job offer!\n",
      "✅ [0.77] - My job is paying my coworker more than me. What do I do?\n",
      "✅ [0.69] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "❌ [0.2] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "❌ [0.04] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [36:21, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300/607 | Last 50 batch train NLL: 0.6209905362129211 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [36:38, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "✅ [0.78] - Started searching for jobs and struggling\n",
      "❌ [0.03] - Just received a new job offer!\n",
      "❌ [0.02] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.3] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "❌ [0.2] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.76] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [1:01:39, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400/607 | Last 50 batch train NLL: 0.5944710719585419 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [1:02:00, 17.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "❌ [0.03] - Started searching for jobs and struggling\n",
      "✅ [0.78] - Just received a new job offer!\n",
      "❌ [0.19] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.2] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "✅ [0.77] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "❌ [0.02] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [1:28:03, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500/607 | Last 50 batch train NLL: 0.5819393742084503 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [1:28:21, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "❌ [0.03] - Started searching for jobs and struggling\n",
      "❌ [0.19] - Just received a new job offer!\n",
      "✅ [0.78] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.19] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "❌ [0.01] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.78] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [1:52:03, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600/607 | Last 50 batch train NLL: 0.6541057634353638 | LR: 3e-05 | Mem: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [1:52:21, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "✅ [0.75] - Started searching for jobs and struggling\n",
      "❌ [0.21] - Just received a new job offer!\n",
      "❌ [0.07] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.21] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "✅ [0.71] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "❌ [0.03] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "607it [1:53:42, 11.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 383.15702894330025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [22:43,  9.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Logging and eval\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m eval_res \u001b[38;5;241m=\u001b[39m \u001b[43meval_performance_on_ds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     58\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_res})\n",
      "File \u001b[1;32mD:\\OneDrive\\__Projects\\labor-market-finetune\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36meval_performance_on_ds\u001b[1;34m(model, ds, batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, b \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dl)):\n\u001b[0;32m     16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m---> 17\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     label_ids \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     20\u001b[0m     total_obs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_ids)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "# TRY LOWERING TO 1e-5 or 2e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5) # 5e-5\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.5)                                                                                                  \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "f = plotly.graph_objects.FigureWidget().add_scatter(x = [], y = [])\n",
    "display(f)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'***** Epoch {epoch} ')\n",
    "    torch.cuda.empty_cache() \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "        loss = F.cross_entropy(outputs['logits'], batch['labels'].to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging and eval\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        train_losses.append((epoch, step, loss.item()))\n",
    "\n",
    "        if step % 100 == 0 and (step > 0 or epoch > 0): \n",
    "            print(\n",
    "                f\"Step {step}/{len(train_dl)} | \" +\n",
    "                f\"Last 50 batch train NLL: {np.mean([t[2] for t in train_losses][-50:])} | \" +\n",
    "                f\"LR: {optimizer.param_groups[0]['lr']} | \" + \n",
    "                f\"Mem: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\"\n",
    "            )\n",
    "            \n",
    "            examples_res = eval_performance_on_examples(model, test_examples)\n",
    "            print(examples_res)\n",
    "            model.train()\n",
    "\n",
    "            losses_df =\\\n",
    "                pd.DataFrame(train_losses, columns = ['epoch', 'step', 'train_loss'])\\\n",
    "                .assign(i = lambda df: range(len(df)), train_loss_roll = lambda df: df['train_loss'].rolling(window = 50).mean())\\\n",
    "                .dropna(axis = 0)\n",
    "            f.data[0].x = losses_df['i'].tolist()\n",
    "            f.data[0].y = losses_df['train_loss_roll'].tolist()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Logging and eval\n",
    "    print(f'Epoch loss: {epoch_loss}')\n",
    "    eval_res = eval_performance_on_ds(model, val_ds)\n",
    "    model.train()\n",
    "    \n",
    "    val_losses.append({**{'epoch': epoch}, **eval_res})\n",
    "        \n",
    "    # Save ts and ckpt    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses\n",
    "    }, f\"{save_dir}/epoch_{str(epoch).rjust(3, '0')}.ckpt\")\n",
    "    \n",
    "    for ex in val_dl:\n",
    "        ex\n",
    "    model_scripted = torch.jit.trace(model, (ex['input_ids'].to(device), ex['attention_mask'].to(device)), strict = False)\n",
    "    model_scripted.save(f\"{save_dir}/epoch_{str(epoch).rjust(3, '0')}.pt\") # Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eda039-c7e2-4c21-9791-c804426a8adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cbdc8-6689-4101-a3b6-12a41f736853",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48758b66-f63f-4ae0-9fff-fa6098c45b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print performance log\n",
    "# import plotly.express as px\n",
    "\n",
    "# losses_df =\\\n",
    "#     pd.DataFrame(train_losses, columns = ['epoch', 'iter', 'train_loss'])\\\n",
    "#     .assign(train_loss_roll = lambda df: df['train_loss'].rolling(window = 2).mean())\\\n",
    "#     .melt(value_vars = ['train_loss_roll'], id_vars = 'iter')\\\n",
    "#     .dropna(axis = 0)\\\n",
    "#     .reset_index(drop = True)\n",
    "#     .merge(pd.DataFrame(test_losses, columns = ['iter', 'test_loss']), how = 'left', on = 'iter')\\\n",
    "\n",
    "# display(px.scatter(losses_df, x = 'iter', y = 'value', color = 'variable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d106e5-36e3-496a-a604-56cf8d703c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type = TaskType.SEQ_CLS, r = 4, lora_alpha = 1, lora_dropout = 0.1\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "# model.print_trainable_parameters()\n",
    "# print(model.roberta.encoder.layer[0].attention.self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
