{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d998e535-0f61-4889-9954-80bdfbac312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_ID = 'financial_health_v1'\n",
    "LABEL_KEY = 'financial_sentiment'\n",
    "\n",
    "from helpers.loaders import load_config\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda')\n",
    "label_encoding_map, test_examples = load_config('label_maps.yaml', prompt_id = PROMPT_ID, label_key = LABEL_KEY) # Get config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1348615-ec12-40cc-8a8d-1c4726af6c05",
   "metadata": {},
   "source": [
    "## Get Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c34069d-d622-4fda-b4ec-ca305ab54eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11685891"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels = len(label_encoding_map)).to(device)\n",
    "\n",
    "# Num params\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bac04-fa74-403a-9fdb-18c7b8789f1c",
   "metadata": {},
   "source": [
    "## Get Data & Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d9d7c5-ed8f-4711-961d-62a446a5d92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "from helpers.db import get_postgres_query\n",
    "\n",
    "raw_data = get_postgres_query(\n",
    "    f\"\"\"\n",
    "    WITH t0 AS (\n",
    "        SELECT \n",
    "            a.post_id, a.label_value AS value, a.label_rationale AS rationale,\n",
    "            CONCAT(TRIM(b.title), '\\n', REGEXP_REPLACE(TRIM(b.selftext), '[\\t\\n\\r]', ' ', 'g')) AS input_text\n",
    "        FROM text_scraper_reddit_llm_scores_v2 a\n",
    "        INNER JOIN text_scraper_reddit_scrapes b\n",
    "            ON a.scrape_id = b.scrape_id\n",
    "        WHERE \n",
    "            a.PROMPT_ID = '{PROMPT_ID}' \n",
    "            AND a.label_key = '{LABEL_KEY}'\n",
    "    )\n",
    "    -- Select where expected token count <= 512\n",
    "    SELECT * \n",
    "    FROM t0\n",
    "    WHERE ARRAY_LENGTH(REGEXP_SPLIT_TO_ARRAY(input_text, '\\\\s+'), 1) * 1.5 <= 512\n",
    "    \"\"\"\n",
    "    ).merge(label_encoding_map, how = 'inner', on = 'value')\n",
    "\n",
    "# 20k total, 16k train. Overweight low-frequency label to the maximum extent possible.\n",
    "input_data =\\\n",
    "    raw_data\\\n",
    "    .sample(n = int(16000 * 1/.8), weights = 1/raw_data.groupby('value')['value'].transform('count')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae424bd-1300-4326-beb2-7bb381ea655f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_encode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "label_encode       \n",
       "0                67\n",
       "1                67\n",
       "2                66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.groupby('label_encode').agg(count = ('post_id', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0a7f61-6955-4918-920e-5ef55223cad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>value</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>t3_pyb8qc</td>\n",
       "      <td>strong</td>\n",
       "      <td>The user is financially independent and consid...</td>\n",
       "      <td>Retire now or work another ten years?\\nMight n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30072</th>\n",
       "      <td>94g9rr</td>\n",
       "      <td>strong</td>\n",
       "      <td>The user is in a very stable financial situati...</td>\n",
       "      <td>How to invest $100k\\nHi.   We are in a very st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13462</th>\n",
       "      <td>t3_hyl7v3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The user is seeking advice on a career change ...</td>\n",
       "      <td>Should I leave my current job for a state job ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25450</th>\n",
       "      <td>t3_wggfim</td>\n",
       "      <td>weak</td>\n",
       "      <td>The user is facing financial uncertainty and p...</td>\n",
       "      <td>What do we do when our only source of income d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29982</th>\n",
       "      <td>t3_innhjv</td>\n",
       "      <td>strong</td>\n",
       "      <td>The user received a significant pay raise by s...</td>\n",
       "      <td>Question about credit cards.\\nI have a quick q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         post_id    value                                          rationale  \\\n",
       "30158  t3_pyb8qc   strong  The user is financially independent and consid...   \n",
       "30072     94g9rr   strong  The user is in a very stable financial situati...   \n",
       "13462  t3_hyl7v3  neutral  The user is seeking advice on a career change ...   \n",
       "25450  t3_wggfim     weak  The user is facing financial uncertainty and p...   \n",
       "29982  t3_innhjv   strong  The user received a significant pay raise by s...   \n",
       "\n",
       "                                              input_text  label_encode  \n",
       "30158  Retire now or work another ten years?\\nMight n...             1  \n",
       "30072  How to invest $100k\\nHi.   We are in a very st...             1  \n",
       "13462  Should I leave my current job for a state job ...             2  \n",
       "25450  What do we do when our only source of income d...             0  \n",
       "29982  Question about credit cards.\\nI have a quick q...             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep Datasets & Dataloader\n",
    "from helpers.loaders import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "B = 16\n",
    "\n",
    "train_df, test_df = train_test_split(input_data, test_size = .2, random_state = 1234)\n",
    "train_ds, test_ds = [TextDataset(tokenizer, x['input_text'].tolist(), x['label_encode'].tolist()) for x in [train_df, test_df]]\n",
    "train_dl, test_dl = [DataLoader(x, batch_size = B) for x in [train_ds, test_ds]]\n",
    "\n",
    "examples_ds = TextDataset(tokenizer, [x['text'] for x in test_examples], [x['label'] for x in test_examples])\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70851791-8bfe-4e07-8c18-e411e31153a7",
   "metadata": {},
   "source": [
    "## Test Initial Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80490ae2-1492-47af-a229-be9d9c6e627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_nll': 1.0935607, 'accuracy': 0.275, 'count': 40}\n",
      "Correct: 4/9\n",
      "❌ [0.35] - Started searching for jobs and struggling\n",
      "❌ [0.26] - Just received a new job offer with a big pay raise!\n",
      "✅ [0.38] - My job is paying my coworker more than me. What do I do?\n",
      "✅ [0.38] - Struggling to manage my credit card debt. I'm in $10k debt and they just keep piling up.\n",
      "❌ [0.36] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.41] - Best budgeting app to use? Looking for a replacement for Mint.\n",
      "❌ [0.37] - As a recent college graduate, I thought it wouldn't be that hard to find a job that paid $20 an hour that but I was wrong. There are no entry level jobs in my field or any job that could potentially get my foot in the door pay so little. What is the point of having a college degree if full time jobs won't even allow me to move out and rent a room.\n",
      "✅ [0.37] - What would be considered a decent salary for an apartment costing $1000 per month?\n",
      "Title says it all. Whatâ€™s a decent one (while still having fun money, can save, feel comfortable)?? And what would be the minimum salary for the same apartment, where I could still get by, but fun would be decreased significantly/eating habits would change. \n",
      "❌ [0.31] - Pretty large raise at work\n",
      "I am a 24-year-old working as an HR Assistant/ Recruiter at a well-endowed Non-Profit. I finished an MBA (that was paid for in full by my org) I almost immediately received a massive raise that increased my comp from 50k to 65k. I also work a part-time 1-day week job that will net just shy of 5K this year. I pay around 1K a month for rent and have about 56k remaining in private student loans. Does anyone have any advice for paying down my loans while growing my bank account? I also maintain a 403B and a Roth that I would consider increasing my contributions but would like to grow savings first due to the expensive city I live in.\n"
     ]
    }
   ],
   "source": [
    "from helpers.loaders import eval_performance, eval_performance_as_str\n",
    "\n",
    "print(eval_performance(model, test_ds, device, batch_size = 16, verbose = True))\n",
    "print(eval_performance_as_str(model, examples_ds, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58139a-fb03-4d2c-a6d7-8181e3c3905d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8863c957-b8a9-420b-b6e1-8f656e57b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train confs\n",
    "conf = {\n",
    "    'epochs': 5,\n",
    "    'optim_lr': 2e-5,\n",
    "    'sched_gamma': .5,\n",
    "    'sched_steps': 400 # Drops every 400 * 16 iters\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = conf['optim_lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = conf['sched_steps'], gamma = conf['sched_gamma'])                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a2c8f6-e2b4-4aee-998a-72d8a99f916b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 8.589410304]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.352273408, 8.589410304]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create save dir\n",
    "from helpers.storage import create_save_dir\n",
    "import json\n",
    "\n",
    "save_dir = create_save_dir(prompt_id = PROMPT_ID, label_key = LABEL_KEY)\n",
    "with open(f'{save_dir}/conf.json', \"w\") as outfile:\n",
    "    outfile.write(json.dumps(conf, indent = 4))\n",
    "\n",
    "print([x/1e9 for x in torch.cuda.mem_get_info()])\n",
    "torch.cuda.empty_cache()\n",
    "[x/1e9 for x in torch.cuda.mem_get_info()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70feffa6-e7fd-48b2-a09c-b53aa2cc3ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c1fd4856494827a221bf3dfc387cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'train', 'type': 'scatter', 'uid': 'cac16314-a498-4acc-a653-b98434b172ff', 'x': [], 'y': []},\n",
       "             {'name': 'test', 'type': 'scatter', 'uid': '9aa01bab-2822-4bab-9c0a-239847edce93', 'x': [], 'y': []}],\n",
       "    'layout': {'shapes': [{'type': 'line', 'x0': 0, 'x1': 0, 'xref': 'x', 'y0': 0, 'y1': 1, 'yref': 'y domain'},\n",
       "                          {'type': 'line', 'x0': 10, 'x1': 10, 'xref': 'x', 'y0': 0, 'y1': 1, 'yref': 'y domain'},\n",
       "                          {'type': 'line', 'x0': 20, 'x1': 20, 'xref': 'x', 'y0': 0, 'y1': 1, 'yref': 'y domain'},\n",
       "                          {'type': 'line', 'x0': 30, 'x1': 30, 'xref': 'x', 'y0': 0, 'y1': 1, 'yref': 'y domain'},\n",
       "                          {'type': 'line', 'x0': 40, 'x1': 40, 'xref': 'x', 'y0': 0, 'y1': 1, 'yref': 'y domain'}],\n",
       "               'template': '...'}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:12,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/10 | Train Loss: 0.9848301952535455 | Test Loss: 0.9924437999725342 | LR: 2e-05 | RAM: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bongohead\\AppData\\Local\\Temp\\ipykernel_16828\\1571102487.py:42: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "1it [00:09,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8/9\n",
      "✅ [0.42] - Started searching for jobs and struggling\n",
      "✅ [0.38] - Just received a new job offer with a big pay raise!\n",
      "❌ [0.27] - My job is paying my coworker more than me. What do I do?\n",
      "✅ [0.45] - Struggling to manage my credit card debt. I'm in $10k debt and they just keep piling up.\n",
      "✅ [0.43] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.43] - Best budgeting app to use? Looking for a replacement for Mint.\n",
      "✅ [0.49] - As a recent college graduate, I thought it wouldn't be that hard to find a job that paid $20 an hour that but I was wrong. There are no entry level jobs in my field or any job that could potentially get my foot in the door pay so little. What is the point of having a college degree if full time jobs won't even allow me to move out and rent a room.\n",
      "✅ [0.5] - What would be considered a decent salary for an apartment costing $1000 per month?\n",
      "Title says it all. Whatâ€™s a decent one (while still having fun money, can save, feel comfortable)?? And what would be the minimum salary for the same apartment, where I could still get by, but fun would be decreased significantly/eating habits would change. \n",
      "✅ [0.43] - Pretty large raise at work\n",
      "I am a 24-year-old working as an HR Assistant/ Recruiter at a well-endowed Non-Profit. I finished an MBA (that was paid for in full by my org) I almost immediately received a massive raise that increased my comp from 50k to 65k. I also work a part-time 1-day week job that will net just shy of 5K this year. I pay around 1K a month for rent and have about 56k remaining in private student loans. Does anyone have any advice for paying down my loans while growing my bank account? I also maintain a 403B and a Roth that I would consider increasing my contributions but would like to grow savings first due to the expensive city I live in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:13,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/10 | Train Loss: 0.8880707962172372 | Test Loss: 0.9721834659576416 | LR: 2e-05 | RAM: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bongohead\\AppData\\Local\\Temp\\ipykernel_16828\\1571102487.py:42: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "1it [00:09,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 7/9\n",
      "✅ [0.42] - Started searching for jobs and struggling\n",
      "✅ [0.55] - Just received a new job offer with a big pay raise!\n",
      "❌ [0.2] - My job is paying my coworker more than me. What do I do?\n",
      "✅ [0.47] - Struggling to manage my credit card debt. I'm in $10k debt and they just keep piling up.\n",
      "❌ [0.38] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "✅ [0.43] - Best budgeting app to use? Looking for a replacement for Mint.\n",
      "✅ [0.56] - As a recent college graduate, I thought it wouldn't be that hard to find a job that paid $20 an hour that but I was wrong. There are no entry level jobs in my field or any job that could potentially get my foot in the door pay so little. What is the point of having a college degree if full time jobs won't even allow me to move out and rent a room.\n",
      "✅ [0.51] - What would be considered a decent salary for an apartment costing $1000 per month?\n",
      "Title says it all. Whatâ€™s a decent one (while still having fun money, can save, feel comfortable)?? And what would be the minimum salary for the same apartment, where I could still get by, but fun would be decreased significantly/eating habits would change. \n",
      "✅ [0.6] - Pretty large raise at work\n",
      "I am a 24-year-old working as an HR Assistant/ Recruiter at a well-endowed Non-Profit. I finished an MBA (that was paid for in full by my org) I almost immediately received a massive raise that increased my comp from 50k to 65k. I also work a part-time 1-day week job that will net just shy of 5K this year. I pay around 1K a month for rent and have about 56k remaining in private student loans. Does anyone have any advice for paying down my loans while growing my bank account? I also maintain a 403B and a Roth that I would consider increasing my contributions but would like to grow savings first due to the expensive city I live in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:14,  7.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/10 | Train Loss: 0.7730229391205695 | Test Loss: 0.9322282671928406 | LR: 2e-05 | RAM: 0.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:09, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 40\u001b[0m\n\u001b[0;32m     32\u001b[0m test_losses\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m: step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: test_eval_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_nll\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dl)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean([t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mt\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mtrain_losses][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43meval_performance_as_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Update graph\u001b[39;00m\n\u001b[0;32m     42\u001b[0m losses_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m     43\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(train_losses)\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m.\u001b[39mdropna(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     44\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(test_losses)\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m ])\u001b[38;5;241m.\u001b[39massign(i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m df: (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl)) \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)     \n",
      "File \u001b[1;32mD:\\OneDrive\\__Projects\\labor-market-finetune\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\OneDrive\\__Projects\\labor-market-finetune\\helpers\\loaders.py:123\u001b[0m, in \u001b[0;36meval_performance_as_str\u001b[1;34m(model, ds, device)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dl):\n\u001b[0;32m    122\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m--> 123\u001b[0m     softmax \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    124\u001b[0m     label \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    126\u001b[0m     is_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(softmax) \u001b[38;5;241m==\u001b[39m label \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Known to work well: 3e-5 with no clipping; 2e-5 with clipping, gamma=.5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "f = plotly.graph_objects.FigureWidget().add_scatter(name = 'train', x = [], y = []).add_scatter(name = 'test', x = [], y = [])\n",
    "for e in range(conf['epochs']): f.add_vline(x = e * len(train_dl))\n",
    "display(f)\n",
    "\n",
    "for epoch in range(conf['epochs']):\n",
    "    print(f'***** Epoch {epoch + 1} ')\n",
    "    torch.cuda.empty_cache() \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dl)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "        loss = F.cross_entropy(outputs['logits'], batch['labels'].to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Logging and eval\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        train_losses.append({'epoch': epoch, 'step': step, 'loss': loss.item()})\n",
    "        if step % 50 == 0 and (step > 0 or epoch > 0): \n",
    "            test_eval_res = eval_performance(model, test_ds, device, batch_size = 16, verbose = False)\n",
    "            test_losses.append({'epoch': epoch, 'step': step, 'loss': test_eval_res['mean_nll']})\n",
    "            print(\n",
    "                f\"Step {step}/{len(train_dl)} | \" +\n",
    "                f\"Train Loss: {np.mean([t['loss'] for t in train_losses][-50:])} | \" +\n",
    "                f\"Test Loss: {test_losses[-1]['loss']} | \" +\n",
    "                f\"LR: {optimizer.param_groups[0]['lr']} | \" + \n",
    "                f\"RAM: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\"\n",
    "            )\n",
    "            print(eval_performance_as_str(model, examples_ds, device))\n",
    "            # Update graph\n",
    "            losses_df = pd.concat([\n",
    "                pd.DataFrame(train_losses).assign(type = 'train', loss = lambda df: df['loss'].rolling(window = 50).mean()).dropna(axis = 0),\n",
    "                pd.DataFrame(test_losses).assign(type = 'test')\n",
    "            ]).assign(i = lambda df: (df['epoch'] * len(train_dl)) + df['step'] + 1)     \n",
    "            f.data[0].x, f.data[1].x = [losses_df[losses_df['type'] == j]['i'].tolist() for j in ['train', 'test']]\n",
    "            f.data[0].y, f.data[1].y = [losses_df[losses_df['type'] == j]['loss'].tolist() for j in ['train', 'test']]\n",
    "\n",
    "    # Save ts and ckpt \n",
    "    torch.save({\n",
    "        'epoch': epoch, 'step': step, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses, 'test_losses': test_losses\n",
    "    }, f\"{save_dir}/epoch_{str(epoch + 1).rjust(3, '0')}.ckpt\")\n",
    "    \n",
    "    ex = next(iter(test_dl))\n",
    "    model_scripted = torch.jit.trace(model, (ex['input_ids'].to(device), ex['attention_mask'].to(device)), strict = False)\n",
    "    model_scripted.save(f\"{save_dir}/epoch_{str(epoch + 1).rjust(3, '0')}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d106e5-36e3-496a-a604-56cf8d703c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type = TaskType.SEQ_CLS, r = 4, lora_alpha = 1, lora_dropout = 0.1\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "# model.print_trainable_parameters()\n",
    "# print(model.roberta.encoder.layer[0].attention.self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
