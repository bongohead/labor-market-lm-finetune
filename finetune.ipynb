{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d998e535-0f61-4889-9954-80bdfbac312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFY_TARGET = 'job_search_status'\n",
    "PROMPT_VERSION = 1\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bac04-fa74-403a-9fdb-18c7b8789f1c",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b7a91f-3eaf-431b-be73-5ede44131c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label encodings\n",
    "import yaml\n",
    "with open('label_maps.yaml', 'r') as file:\n",
    "    yaml_dict = [x for x in yaml.safe_load(file)['v' + str(PROMPT_VERSION)] if x['model'] == CLASSIFY_TARGET][0]\n",
    "\n",
    "label_encoding_map = pd.DataFrame.from_dict(yaml_dict['map'])\n",
    "test_examples = yaml_dict['examples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d9d7c5-ed8f-4711-961d-62a446a5d92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>value</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_118xr9s</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering going back to the same...</td>\n",
       "      <td>Would you go back to a company you had already...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_rwpsfy</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user expresses frustration with talent acq...</td>\n",
       "      <td>MY RESUME OUTLINES MY EXPERIENCE, SO DO NOT SE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_10p8ox3</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering leaving their current ...</td>\n",
       "      <td>Wait to be fired or quit?\\nLong story short—I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_17japq3</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user is considering leaving their current ...</td>\n",
       "      <td>My boss is always shouting at me\\nHello, I jus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_vh2pl2</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user mentions struggling to find a part-ti...</td>\n",
       "      <td>How the hell do I get a job as a 15 year old w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>t3_pjb07w</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user has accepted a full-time position at ...</td>\n",
       "      <td>What advice do you have on healing from a toxi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>t3_ypqi89</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions accepting a new job within t...</td>\n",
       "      <td>Got a new job and agreed to start January 2nd ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8212</th>\n",
       "      <td>t3_oyjw7m</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user mentions receiving a job offer.</td>\n",
       "      <td>Job search finally over!\\nAfter many months, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>t3_zedntw</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user has received a job offer.</td>\n",
       "      <td>Should I accept a job if the pay is $14k less ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8214</th>\n",
       "      <td>t3_p6yw9s</td>\n",
       "      <td>received offer/started new job</td>\n",
       "      <td>The user has received a job offer from a local...</td>\n",
       "      <td>Job offer after a 20 minute interview? Should ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8215 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         post_id                           value  \\\n",
       "0     t3_118xr9s    searching/considering search   \n",
       "1      t3_rwpsfy    searching/considering search   \n",
       "2     t3_10p8ox3    searching/considering search   \n",
       "3     t3_17japq3    searching/considering search   \n",
       "4      t3_vh2pl2    searching/considering search   \n",
       "...          ...                             ...   \n",
       "8210   t3_pjb07w  received offer/started new job   \n",
       "8211   t3_ypqi89  received offer/started new job   \n",
       "8212   t3_oyjw7m  received offer/started new job   \n",
       "8213   t3_zedntw  received offer/started new job   \n",
       "8214   t3_p6yw9s  received offer/started new job   \n",
       "\n",
       "                                              rationale  \\\n",
       "0     The user is considering going back to the same...   \n",
       "1     The user expresses frustration with talent acq...   \n",
       "2     The user is considering leaving their current ...   \n",
       "3     The user is considering leaving their current ...   \n",
       "4     The user mentions struggling to find a part-ti...   \n",
       "...                                                 ...   \n",
       "8210  The user has accepted a full-time position at ...   \n",
       "8211  The user mentions accepting a new job within t...   \n",
       "8212           The user mentions receiving a job offer.   \n",
       "8213                 The user has received a job offer.   \n",
       "8214  The user has received a job offer from a local...   \n",
       "\n",
       "                                             input_text  label_encode  \n",
       "0     Would you go back to a company you had already...             1  \n",
       "1     MY RESUME OUTLINES MY EXPERIENCE, SO DO NOT SE...             1  \n",
       "2     Wait to be fired or quit?\\nLong story short—I ...             1  \n",
       "3     My boss is always shouting at me\\nHello, I jus...             1  \n",
       "4     How the hell do I get a job as a 15 year old w...             1  \n",
       "...                                                 ...           ...  \n",
       "8210  What advice do you have on healing from a toxi...             0  \n",
       "8211  Got a new job and agreed to start January 2nd ...             0  \n",
       "8212  Job search finally over!\\nAfter many months, m...             0  \n",
       "8213  Should I accept a job if the pay is $14k less ...             0  \n",
       "8214  Job offer after a 20 minute interview? Should ...             0  \n",
       "\n",
       "[8215 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv(Path().absolute() / '.env', override = True)\n",
    "\n",
    "def get_query(query: str) -> pd.DataFrame: \n",
    "    engine = create_engine(\n",
    "        \"postgresql+psycopg2://{user}:{password}@{host}/{dbname}\".format(\n",
    "           dbname = os.getenv('DB_DATABASE'),\n",
    "           user = os.getenv('DB_USERNAME'),\n",
    "           password = os.getenv('DB_PASSWORD'),\n",
    "           host = os.getenv('DB_SERVER')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    pg = engine.connect()\n",
    "    res = pd.read_sql(query, con = pg)\n",
    "    pg.close()\n",
    "    \n",
    "    return res\n",
    "\n",
    "input_data = get_query(\n",
    "    f\"\"\"\n",
    "    WITH t0 AS (\n",
    "        SELECT \n",
    "            a.post_id, a.label_value AS value, a.label_rationale AS rationale,\n",
    "            CONCAT(TRIM(b.title), '\\n', REGEXP_REPLACE(TRIM(b.selftext), '[\\t\\n\\r]', ' ', 'g')) AS input_text\n",
    "        FROM text_scraper_reddit_llm_scores a\n",
    "        INNER JOIN text_scraper_reddit_scrape b\n",
    "            ON a.scrape_id = b.id\n",
    "        WHERE a.prompt_version = 1 AND a.label_key = '{CLASSIFY_TARGET}'\n",
    "    )\n",
    "    -- Select where expected token count <= 512\n",
    "    SELECT * FROM t0\n",
    "    WHERE ARRAY_LENGTH(REGEXP_SPLIT_TO_ARRAY(input_text, '\\\\s+'), 1) * 1.5 <= 512\n",
    "    \"\"\"\n",
    "    ).merge(label_encoding_map, how = 'inner', on = 'value')\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfc4c5-bff1-4697-9e6b-5c7034b5786c",
   "metadata": {},
   "source": [
    "## Get Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a561cbc-78ce-4659-b959-61f28de1772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11685891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels = len(label_encoding_map)).to(device)\n",
    "\n",
    "# Num params\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d85c79-8f1f-4ed2-985a-a877f324fe0e",
   "metadata": {},
   "source": [
    "## Create Datasets & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0a7f61-6955-4918-920e-5ef55223cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Batch size\n",
    "B = 16\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, texts, labels = None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.inputs = self.tokenize_and_encode()\n",
    "        \n",
    "        if labels is not None:\n",
    "            self.labels = torch.tensor(labels, dtype = torch.long)\n",
    "        else:\n",
    "            self.labels = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def tokenize_and_encode(self):\n",
    "        return self.tokenizer(\n",
    "            self.texts,\n",
    "            add_special_tokens = True,\n",
    "            max_length = 512,\n",
    "            truncation = True,\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: vals[idx] for key, vals in self.inputs.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_df, val_df = train_test_split(input_data, test_size = .2, random_state = 1)\n",
    "train_ds, val_ds = [TextDataset(tokenizer, x['input_text'].tolist(), x['label_encode'].tolist()) for x in [train_df, val_df]]\n",
    "train_dl, val_dl = [DataLoader(x, batch_size = B) for x in [train_ds, val_ds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c392730-58c7-40b8-b5e2-25905f88bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = received offer/started new job\n",
    "# 1 = searching/considering search\n",
    "# 2 = not/unknown\n",
    "# print(val_ds.texts[6], val_ds.labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a77ea3e-44b3-42c6-8f0c-e029c46225b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>value</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>t3_171ap78</td>\n",
       "      <td>searching/considering search</td>\n",
       "      <td>The user mentions feeling unhappy in their cur...</td>\n",
       "      <td>I f-ed up so bad by relocating\\nIt's been a mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                         value  \\\n",
       "74  t3_171ap78  searching/considering search   \n",
       "\n",
       "                                            rationale  \\\n",
       "74  The user mentions feeling unhappy in their cur...   \n",
       "\n",
       "                                           input_text  label_encode  \n",
       "74  I f-ed up so bad by relocating\\nIt's been a mo...             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70851791-8bfe-4e07-8c18-e411e31153a7",
   "metadata": {},
   "source": [
    "## Create Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80490ae2-1492-47af-a229-be9d9c6e627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1643it [00:36, 45.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_nll': 0.9460146, 'accuracy': 0.751065124771759, 'count': 1643}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_performance_on_ds(model, ds, batch_size = 16):\n",
    "    \"\"\"\n",
    "    Test model performance on evaluation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_obs = 0\n",
    "    total_correct = 0\n",
    "    nlls = []\n",
    "\n",
    "    dl = DataLoader(ds, batch_size = batch_size)\n",
    "    \n",
    "    for step, b in tqdm(enumerate(dl)):\n",
    "        outputs = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "        logits = outputs['logits'].cpu()\n",
    "        label_ids = b['labels'].cpu()\n",
    "        \n",
    "        total_obs += len(label_ids)\n",
    "        total_correct += np.sum(np.where(np.argmax(logits, axis = 1) == label_ids, 1, 0))\n",
    "        nlls.append(F.cross_entropy(logits, label_ids))\n",
    "    \n",
    "    res = {'mean_nll': np.mean(nlls), 'accuracy': total_correct/total_obs, 'count': total_obs}\n",
    "    return res\n",
    "\n",
    "eval_performance_on_ds(model, val_ds, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383cbbc1-ae63-4b6e-8a46-c6f9e562856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2/6\n",
      "✅ [0.59] - Started searching for jobs and struggling\n",
      "❌ [0.24] - Just received a new job offer!\n",
      "❌ [0.21] - My job is paying my coworker more than me. What do I do?\n",
      "❌ [0.14] - Recruiters really tick me off\n",
      "Its 9am on a weekend and I'm already ticked off. I came across a post on LinkedIn that said recruiters should dress up as ghosts because they ghost candidates. Do recruiters really think this kind of stuff is funny?\n",
      "✅ [0.6] - Emotionally exhausted from this BS market\n",
      "I just need to rant. I never cried so much within a week until now. I have bills to pay, rent is over 2k for a studio, there are no jobs here. I am so tired because this job market is exhausting and everyone is saying its fine.\n",
      "❌ [0.31] - Mind blowing \"counter\" from employer\n",
      "So I'm officially employed as a sales rep on $47k/year, but I've been doing the responsibilities and tasks of the sales manager AND operations manager all year. Both of these official positions have technically been available, but my boss just hasn't bothered hiring for them. I recently got a new job that I start in 2 weeks, which is going to pay me just over $99k/year with additional benefits and allowances. The day after I resigned last week, my boss came at me with the \"official\" promotion to the role I'm doing - $55K. I declined, obviously. He seemed shocked, told me that the money shouldn't be a factor, that I've built up such a great reputation here I'd be throwing my \"career\" away (I've been there for less than 2 years). I told him that it's insulting at this point, and that if he had offered me the position a few months ago I wouldn't have started job searching and would've been elated. I advised him to reward people when it's due, not when you're going to lose them. Now as a result, the location I work at is going to be shut down because he can't find anyone to replace me and the other managers are leaving with me. Karma is sweet. \n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_performance_on_examples(model, examples):\n",
    "    \"\"\"\n",
    "    Run inference on a handful of predefined examples. Returns a printable string.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    str = ''\n",
    "    \n",
    "    inference_examples = [x['text'] for x in test_examples]\n",
    "    labels = [x['label'] for x in test_examples]\n",
    "    inference_dl = DataLoader(TextDataset(tokenizer, inference_examples, labels), 1)\n",
    "    \n",
    "    for i, b in enumerate(inference_dl):\n",
    "        out = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "        softmax = F.softmax(out['logits'].detach().cpu().flatten(), dim = 0)\n",
    "        label = b['labels'].cpu()\n",
    "\n",
    "        is_correct = 1 if np.argmax(softmax) == label else 0\n",
    "        total_correct = total_correct + is_correct\n",
    "        str += (f'\\n{\"✅\" if is_correct == 1 else \"❌\"} {softmax[label].numpy().round(2)} - {inference_examples[i]}')\n",
    "\n",
    "    return f\"Correct: {total_correct}/{len(inference_examples)}\" + str\n",
    "    \n",
    "print(eval_performance_on_examples(model, test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c47f96-ab83-4020-8e38-1df6a1bad820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5011712, 8.589410304]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.555697152, 8.589410304]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([x/1e9 for x in torch.cuda.mem_get_info()])\n",
    "torch.cuda.empty_cache()\n",
    "[x/1e9 for x in torch.cuda.mem_get_info()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58139a-fb03-4d2c-a6d7-8181e3c3905d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd3dbf4-7ac3-4df6-a188-19bc58c3b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d847e5f534c435eb617b131bc23c5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': 'db036611-2782-41e8-ae72-000e5447a1a2', 'x': [], 'y': []}],\n",
       "    'layout': {'template': '...'}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:26,  7.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Logging and eval\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m+\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend((epoch, step, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m): \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "# TRY LOWERING TO 1e-5 or 2e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5) # 5e-5\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.5)                                                                                                  \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "f = plotly.graph_objects.FigureWidget().add_scatter(x = [], y = [])\n",
    "display(f)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'***** Epoch {epoch} ')\n",
    "    torch.cuda.empty_cache() \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "        loss = F.cross_entropy(outputs['logits'], batch['labels'].to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging and eval\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        train_losses.append((epoch, step, loss.item()))\n",
    "\n",
    "        if step % 100 == 0 and (step > 0 or epoch > 0): \n",
    "            print(\n",
    "                f\"Step {step}/{len(train_dl)} | \" +\n",
    "                f\"Last 50 batch train NLL: {np.mean([t[2] for t in train_losses][-50:])} | \" +\n",
    "                f\"LR: {optimizer.param_groups[0]['lr']} | \" + \n",
    "                f\"Mem: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\"\n",
    "            )\n",
    "            \n",
    "            model.eval()\n",
    "            examples_res = eval_performance_on_examples(model, test_examples)\n",
    "            print(examples_res)\n",
    "            model.train()\n",
    "\n",
    "            losses_df =\\\n",
    "                pd.DataFrame(train_losses, columns = ['epoch', 'step', 'train_loss'])\\\n",
    "                .assign(i = lambda df: range(len(df)), train_loss_roll = lambda df: df['train_loss'].rolling(window = 50).mean())\\\n",
    "                .dropna(axis = 0)\n",
    "            f.data[0].x = losses_df['i'].tolist()\n",
    "            f.data[0].y = losses_df['train_loss_roll'].tolist()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Logging and eval\n",
    "    print(f'Epoch loss: {epoch_loss}')\n",
    "    model.eval()\n",
    "    eval_res = eval_performance_on_ds(model, val_ds)\n",
    "    print(eval_res)\n",
    "        \n",
    "    model.train()\n",
    "    val_losses.append({**{'epoch': epoch}, **eval_res})\n",
    "        \n",
    "    # Export to TorchScript    \n",
    "    for ex in val_dl:\n",
    "        ex\n",
    "\n",
    "    model_scripted = torch.jit.trace(model, (ex['input_ids'].to(device), ex['attention_mask'].to(device)), strict = False)\n",
    "    model_scripted.save(f\"saves/model_{CLASSIFY_TARGET}_epoch_{str(epoch).rjust(3, '0')}.pt\") # Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0b76e-a3fb-4b05-8c55-7625e971d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in val_dl:\n",
    "    ex\n",
    "\n",
    "model_scripted = torch.jit.trace(model, (ex['input_ids'].to(device), ex['attention_mask'].to(device)), strict = False)\n",
    "# Export to TorchScript\n",
    "model_scripted.save(f\"saves/model_{CLASSIFY_TARGET}_epoch_{str(epoch).rjust(3, '0')}.pt\") # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eda039-c7e2-4c21-9791-c804426a8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cbdc8-6689-4101-a3b6-12a41f736853",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b7d0f-f61c-4362-b29e-6d7e96f0e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.jit.load(f'saves/save_{CLASSIFY_TARGET}.pt')\n",
    "loaded.eval()\n",
    "loaded(ex['input_ids'].to(device), ex['attention_mask'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48758b66-f63f-4ae0-9fff-fa6098c45b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print performance log\n",
    "# import plotly.express as px\n",
    "\n",
    "# losses_df =\\\n",
    "#     pd.DataFrame(train_losses, columns = ['epoch', 'iter', 'train_loss'])\\\n",
    "#     .assign(train_loss_roll = lambda df: df['train_loss'].rolling(window = 2).mean())\\\n",
    "#     .melt(value_vars = ['train_loss_roll'], id_vars = 'iter')\\\n",
    "#     .dropna(axis = 0)\\\n",
    "#     .reset_index(drop = True)\n",
    "#     .merge(pd.DataFrame(test_losses, columns = ['iter', 'test_loss']), how = 'left', on = 'iter')\\\n",
    "\n",
    "# display(px.scatter(losses_df, x = 'iter', y = 'value', color = 'variable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d106e5-36e3-496a-a604-56cf8d703c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type = TaskType.SEQ_CLS, r = 4, lora_alpha = 1, lora_dropout = 0.1\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "# model.print_trainable_parameters()\n",
    "# print(model.roberta.encoder.layer[0].attention.self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
